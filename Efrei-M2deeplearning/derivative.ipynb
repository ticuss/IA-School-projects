{"cells":[{"cell_type":"markdown","source":"Rappels dérivés et gradients\n\nLa dérivée représente les variations d'une fonction\n\n$ x \\rightarrow f(x) = 2 * x $ \n\n$ f'(x) = 2 * x $ \n\n\n\n$x_1 = 2$ \n$f'(x_1) = 4 > 0 $\n\nQu'est ce que ça veut dire  ?\n\nça veut dire que la fonction est croissante aux alentours de $ x_1 $. \n\nEt ça veut dire que si on veut se rapprocher du minimum, il suffit de reaprtir de $x_1$ et d'en diminuer la valeur : \n\n\n$ x_2 = x_1 - \\gamma $ \n\nsi $\\gamma$ est assez petit , alors on a des chances \nque $f(x_2) < f(x_1)$ \n\nQue choisir pour $\\gamma$ ?  On va utiliser la dérivée !\n\n\n$\\gamma = \\alpha * f'(x_1) $ \n\n$ x_2 = x_1 - \\alpha * f'(x_1) $ \n\n$f(x_2) < f(x_1)$\n\n","metadata":{"tags":[],"cell_id":"9bfc00c7fb8240398183eff3ee5bf9c0","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Dans la vraie vie on a des fonctions à plusieurs variables \n\n\n$x,y, z \\rightarrow f(x,y,z) = x*y + z  ^2$\n\nOn peut faire pareil que si on a une seule variable, mais il nous faut un équivalent de la dérivée : les dérivées partielles et le gradient.\n\nGradient : vecteur qui contient toutes les dérivées partielle d'une fonction \n\n$\\nabla f $ =  $\\frac{\\partial{f} }{\\partial{x}} $,  $\\frac{\\partial{f} }{\\partial{y}} $,  $\\frac{\\partial{f} }{\\partial{z}} $  ","metadata":{"tags":[],"cell_id":"efc15804405e44a590c79e37ab3a8c01","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"6242e0a1c0a94a5d9ad1e159d5a0eaf6","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Et il se trouve que Pytorch, quand on utilise la fonction backward, nous calcule la valeur numérique des dérivées partielles :\n\n $\\frac{\\partial{f}(x=0.1, y=0.1, z=0.1) }{\\partial{x}} $ \n $\\frac{\\partial{f}(x=0.1, y=0.1, z=0.1) }{\\partial{y}} $\n  $\\frac{\\partial{f}(x=0.1, y=0.1, z=0.1) }{\\partial{z}} $","metadata":{"tags":[],"cell_id":"d0a3ce6e27c54b1e9e2ea0ae5a67d85a","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":" $\\frac{\\partial{f}(x=0.1, y=0.1, z=0.1) }{\\partial{x}} $  : x.grad.data \n  ","metadata":{"tags":[],"cell_id":"97581d6f35954a809b976edfa9163c41","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":" $\\frac{\\partial{f}(x=0.1, y=0.1, z=0.1) }{\\partial{y}} $  : y.grad.data \n  ","metadata":{"tags":[],"cell_id":"809109372fb54ba991f0f1546f5c3559","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Attention : x.grad.data contient la dérivée partielle pas tout le gradient ! \n","metadata":{"tags":[],"cell_id":"cccbf2080b6241d3ad5c10c9b49ebd36","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Un paramètre c'est une quantité qui sert à calculer la prédiction d'un modèle qui va changer de l'entraînement. \n\n\n$ \\hat{y} = \\theta_0 + \\theta_1 * size + \\theta_2 * n_{rooms} + \\theta_3 * garden $","metadata":{"tags":[],"cell_id":"81810f719a3d4f1b90f94cd59c2498b6","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"ad990906bac643f8b272d913262ebadb","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6b859965-b858-4b8d-a841-009599aef86e' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{"is_reactive":false},"orig_nbformat":2,"deepnote_notebook_id":"f1f616a75bbb45a9821ef50c25fdafb8","deepnote_execution_queue":[]}}